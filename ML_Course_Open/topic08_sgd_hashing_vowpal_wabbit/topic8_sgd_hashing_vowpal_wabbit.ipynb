{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Открытый курс по машинному обучению\n",
    "</center>\n",
    "Автор материала: программист-исследователь Mail.ru Group, старший преподаватель Факультета Компьютерных Наук ВШЭ Юрий Кашницкий. Материал распространяется на условиях лицензии [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). Можно использовать в любых целях (редактировать, поправлять и брать за основу), кроме коммерческих, но с обязательным упоминанием автора материала."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Тема 8. Стохастический градиентный спуск, онлайн-обучение, Vowpal Wabbit</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Всем привет! Вот мы постепенно и дошли до продвинутых методов машинного обучения, сегодня обсудим, как вообще подступиться к обучению модели, если данных гигабайты и десятки гигабайт.\n",
    "Обсудим приемы, позволяющие это делать: стохастический градиентный спуск (SGD) и хэширование признаков, посмотрим на примеры применения библиотеки Vowpal Wabbit. Домашнее задание будет как на реализацию SGD-алгоритмов, так и на обучение классификатора вопросов на StackOverflow по выборке в 10 Гб. \n",
    "\n",
    "Поехали!\n",
    "\n",
    "# План\n",
    "- Стохастический градиентный спуск и онлайн-подход к обучению\n",
    "    - Стохастический градиентный спуск\n",
    "    - Онлайн-подход к обучению\n",
    "- Работа с категориальными признаками: Label Encoding, One-Hot Encoding, Hashing trick\n",
    "    - Label Encoding\n",
    "    - One-Hot Encoding\n",
    "    - Хэширование признаков (Hashing trick)\n",
    "- Vowpal Wabbit\n",
    "    - Новости. Бинарная классификация\n",
    "    - Письма. Многоклассовая классификация\n",
    "    - Рецензии к фильмам IMDB\n",
    "    - Классификация вопросов на Stackoverflow "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вначале импортируем сразу все нужные библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.datasets import fetch_20newsgroups, load_files\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Стохастический градиентный спуск и онлайн-подход к обучению\n",
    "## Стохастический градиентный спуск\n",
    "\n",
    "Несмотря на то, что градиентный спуск – одна из первых тем, изучаемых в теории оптимизации и машинном обучении, сложно переоценить важность одной его модификации – стохастического градиентного спуска, который мы часто будем называть просто SGD (Stochastic Gradient Descent). \n",
    "\n",
    "Напомним, что суть градиентного спуска – минимизировать функцию, делая небольшие шаги в сторону наискорейшего убывания функции. Название методу подарил тот факт из математического анализа, что вектор $\\nabla f = (\\frac{\\partial f}{\\partial x_1}, \\ldots \\frac{\\partial f}{\\partial x_n})^T$ частных производных функции $f(x) = f(x_1, \\ldots x_n)$ задает направление наискорейшего возрастания этой функции. Значит, двигаясь в сторону антиградиента функции (вектора, противоположного градиенту), можно уменьшать ее значение быстрее всего. \n",
    "\n",
    "<img src='../../img/snowboard.jpg' width=70%>\n",
    "\n",
    "Это я в Шерегеше – всем катающим советую хотя бы раз в жизни там оказаться. Картинка для успокоения глаз, но с ее помощью можно пояснить интуицию градиентного спуска. Если задача – как можно быстрее спуститься с горы на сноуборде, то нужно в каждой точке выбирать максимальный уклон (если это совместимо с жизнью). Вычисление антиградиента – это и есть оценка крутизны склона в данной точке. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пример**\n",
    "\n",
    "Задачу простой парной регрессии можно решать с помощью градиентного спуска. Предположим, мы прогнозируем одну переменную по другой – рост по весу – и постулируем линейную зависимость роста от веса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "data_demo = pd.read_csv('../../data/weights_heights.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEFCAYAAAAPCDf9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108d29e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(data_demo['Weight'], data_demo['Height']);\n",
    "plt.xlabel('Вес в фунтах')\n",
    "plt.ylabel('Рост в дюймах');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Даны вектор $x$ длины $\\ell$– значения веса для каждого наблюдения (человека) и $y$ – вектор значений роста для каждого наблюдения (человека).\n",
    "\n",
    "Задача: найти такие веса $w_0$ и $w_1$, чтобы при прогнозе роста по весу в виде $y_i = w_0 + w_1 x_i$ (где $y_i$ – $i$-ое значение роста, $x_i$ –  $i$-ое значение веса) минимизировать квадратичную ошибку (можно и среднеквадратичную, но константа $\\frac{1}{\\ell}$ погоды не делает, а $\\frac{1}{2}$ заведена для красоты):\n",
    "$$SE(w_0, w_1) = \\frac{1}{2}\\sum_{i=1}^\\ell(y_i - (w_0 + w_1x_{i}))^2 \\rightarrow min_{w_0,w_1}$$\n",
    "\n",
    "Делать мы это будем с помощью градиентного спуска, посчитав частные производные функции $SE(w_0, w_1)$ по весам в модели – $w_0$ и $w_1$.\n",
    "Итеративная процедура обучения будет задаваться простыми формулами обновления весов (меняем веса так, чтобы длать небольшой, пропорционально малой константе $\\eta$, шаг в сторону антиградиента функции):\n",
    "\n",
    "$$\\begin{array}{rcl} w_0^{(t+1)} = w_0^{(t)} -\\eta \\frac{\\partial SE}{\\partial w_0} |_{t} \\\\  w_1^{(t+1)} = w_1^{(t)} -\\eta \\frac{\\partial SE}{\\partial w_1} |_{t} \\end{array}$$\n",
    "\n",
    "Если обратиться к ручке и бумажке и найти аналитические выражения для частных производных, то получим \n",
    "\n",
    "$$\\begin{array}{rcl} w_0^{(t+1)} = w_0^{(t)} + \\eta \\sum_{i=1}^{\\ell}(y_i - w_0^{(t)} - w_1^{(t)}x_i) \\\\  w_1^{(t+1)} = w_1^{(t)} + \\eta \\sum_{i=1}^{\\ell}(y_i - w_0^{(t)} - w_1^{(t)}x_i)x_i \\end{array}$$\n",
    "\n",
    "И все это довольно хорошо работает (в этой статье мы не будем обсуждать проблемы локальных минимумов, подбора шага градиентного спуска, момент и т.д. – про это и так много написано, можно обратиться к [главе](http://www.deeplearningbook.org/contents/numerical.html) \"Numeric Computation\" книги \"Deep Learning\") пока данных не становится слишком много. Проблема такого подхода в том, что вычисление градиента сводится к суммированию некоторых величин для каждого объекта обучающей выборки. То есть попросту, проблема в том, что итераций алгоритму на практике требуется много, а на каждой итерации веса пересчитываются по формуле, в которой есть сумма по всей выборке вида $\\sum_{i=1}^\\ell$. А что если объектов в выборке миллионы и миллиарды?\n",
    "\n",
    "\n",
    "\n",
    "Суть стохастического градиентного спуска – неформально, выкинуть знак суммы из формул пересчета весов и обновлять их по одному объекту. То есть в нашем случае\n",
    "\n",
    "$$\\begin{array}{rcl} w_0^{(t+1)} = w_0^{(t)} + \\eta (y_i - w_0^{(t)} - w_1^{(t)}x_i) \\\\  w_1^{(t+1)} = w_1^{(t)} + \\eta (y_i - w_0^{(t)} - w_1^{(t)}x_i)x_i \\end{array}$$\n",
    "\n",
    "При таком подходе на каждой итерации уже совсем не гарантировано движение в сторону наискорейшего убывания функции, и итераций может понадобиться на пару порядков больше, чем при обычном градиентном спуске. Зато пересчет весов на каждой итерации делается почти мгновенно. \n",
    "\n",
    "В качестве иллюстрации возьмем картинку Эндрю Ына из его [курса](https://www.coursera.org/learn/machine-learning) машинного обучения.\n",
    "\n",
    "<img src='../../img/sgd_convergence.png'>\n",
    "\n",
    "Нарисованы линии уровня некоторой функции, минимум который мы ищем. Красная кривая изображает изменение весов (на картинке $\\theta_0$ и $\\theta_1$ соответсвуют $w_0$ и $w_1$ в нашем примере). По свойствам градиента направление изменения в каждой точке будет перпендикулярно линиям уровня. При стохастическом подходе на каждой итерации веса меняется менее предсказуемо, порой даже кажется, что некоторые шаги неудачны – уводят от заветного минимума, но в итоге обе процедуры сходятся примерно к одному решению.\n",
    "\n",
    "Сходимость стохатического градиентного спуска к тому же решению, что и у градиентного спуска, является одним из важнейших фактов, доказанных в теории оптимизации. Сейчас в эпоху Deep Data и Big Learning чаще даже градиентным спуском называет именно его стохастическую версию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Онлайн-подход к обучению\n",
    "Стохастический градиентный спуск, будучи одним из методов оптимизации, дает вполне практическое руководство к обучению алгоритмов классификации и регрессии на больших выборках – до сотен гигабайт (в зависимости от имеющейся памяти).\n",
    "\n",
    "В случае парной регрессии, который мы рассмотрели, на диске можно хранить обучающую выборку $(X,y)$ и, не загружая ее в оперативную память (она может попросту не поместиться), считывать объекты по одному и обновлять веса:\n",
    "\n",
    "$$\\begin{array}{rcl} w_0^{(t+1)} = w_0^{(t)} + \\eta (y_i - w_0^{(t)} - w_1^{(t)}x_i) \\\\  w_1^{(t+1)} = w_1^{(t)} + \\eta (y_i - w_0^{(t)} - w_1^{(t)}x_i)x_i \\end{array}$$\n",
    "\n",
    "После обработки всех объектов обучающей выборки, функционал, который мы оптимизируем (квадратичная ошибка в задаче регрессии или, напрмиер, логистическая – в задаче классификации) снизится, но часто нужно несколько десятков проходов по выборке, чтобы он снизился достаточно. \n",
    "\n",
    "Такой подход к обучению моделей часто называют онлайн-обучением, термин появился еще до того, как MOOC-и стали мэйнстримом.\n",
    "\n",
    "<img src=\"../../img/andrew_ng_online_learning.jpg\" width=50%>\n",
    "\n",
    "В этой статье мы не рассматриваем многих нюансов стохастической оптимизации (вот хорошая [статья](https://habrahabr.ru/post/318970/) на Хабре, фундаментально изучить эту тему можно по книге Boyd \"Convex Optimization\"), перейдем скорее к библиотеке Vowpal Wabbit, с помощью которой можно обучать простые модели на огромных выборках за счет стохастической оптимизации и еще одного трюка – хэширования признаков, о котором пойдет речь далее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В библиотеке Scikit-learn классификаторы и регрессоры, обучаемые стохастическим градиентным спуском, реализованы классами `SGDClassifier` и `SGDRegressor` из `sklearn.linear_model`. Частью домашнего задания будет разобраться в них уже после собственной реализации этих простых онлайн-алгоритмов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Работа с категориальными признаками: Label Encoding, One-Hot Encoding, Hashing trick\n",
    "\n",
    "## Label Encoding\n",
    "Подавляющее большинство методов классификации и регрессии сформулированы в терминах евклидовых или метрических пространств, то есть подразумевают представление данных в виде вещественных векторов одинаковой размерности. В реальных данных, однако, не так редки категориальные признаки, принимающие дискретные значения, такие как да/нет или  январь/февраль/.../декабрь. Обсудим то, как работать с такими данными, в частности с помощью линейных моделей, и что делать, если категориальных признаков много, да еще и у каждого куча уникальных значений. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим выборку UCI bank, в которой большая часть признаков – категориальные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>student</td>\n",
       "      <td>single</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>jun</td>\n",
       "      <td>mon</td>\n",
       "      <td>901</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>94.465</td>\n",
       "      <td>-41.8</td>\n",
       "      <td>4.961</td>\n",
       "      <td>5228.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>tue</td>\n",
       "      <td>208</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.444</td>\n",
       "      <td>-36.1</td>\n",
       "      <td>4.963</td>\n",
       "      <td>5228.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>jun</td>\n",
       "      <td>tue</td>\n",
       "      <td>131</td>\n",
       "      <td>5</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>94.465</td>\n",
       "      <td>-41.8</td>\n",
       "      <td>4.864</td>\n",
       "      <td>5228.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jul</td>\n",
       "      <td>tue</td>\n",
       "      <td>404</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>92.469</td>\n",
       "      <td>-33.6</td>\n",
       "      <td>1.044</td>\n",
       "      <td>5076.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>nov</td>\n",
       "      <td>mon</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>93.200</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>4.191</td>\n",
       "      <td>5195.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          job  marital          education  default housing loan  \\\n",
       "0   26      student   single        high.school       no      no   no   \n",
       "1   46       admin.  married  university.degree       no     yes   no   \n",
       "2   49  blue-collar  married           basic.4y  unknown     yes  yes   \n",
       "3   31   technician  married  university.degree       no      no   no   \n",
       "4   42    housemaid  married  university.degree       no     yes   no   \n",
       "\n",
       "     contact month day_of_week  duration  campaign  pdays  previous  \\\n",
       "0  telephone   jun         mon       901         1    999         0   \n",
       "1   cellular   aug         tue       208         2    999         0   \n",
       "2  telephone   jun         tue       131         5    999         0   \n",
       "3   cellular   jul         tue       404         1    999         0   \n",
       "4  telephone   nov         mon        85         1    999         0   \n",
       "\n",
       "      poutcome  emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  \\\n",
       "0  nonexistent           1.4          94.465          -41.8      4.961   \n",
       "1  nonexistent           1.4          93.444          -36.1      4.963   \n",
       "2  nonexistent           1.4          94.465          -41.8      4.864   \n",
       "3  nonexistent          -2.9          92.469          -33.6      1.044   \n",
       "4  nonexistent          -0.1          93.200          -42.0      4.191   \n",
       "\n",
       "   nr.employed  \n",
       "0       5228.1  \n",
       "1       5228.1  \n",
       "2       5228.1  \n",
       "3       5076.2  \n",
       "4       5195.8  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/bank_train.csv')\n",
    "labels = pd.read_csv('../../data/bank_train_target.csv', header=None)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нетрудно заметить, что достаточно много признаков в этом наборе данных не представлены числами. В таком виде данные еще нам не подходят - мы не сможем применять подавляющее большинство доступных нам методов.\n",
    "\n",
    "Чтобы найти решение, давайте рассмотрим признак education:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbsAAAD3CAYAAACEhPq9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLHv/H22MUcQj8ydKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11795fb38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['education'].value_counts().plot.barh();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Естественным решением такой проблемы было бы однозначное отображение каждого значения в уникальное число. К примеру, мы могли бы преобразовать `university.degree` в 0, а `basic.9y` в 1. Эту простую операцию приходится делать часто, поэтому в модуле `preprocessing` библиотеки `sklearn` именно для этой задачи реализован класс `LabelEncoder`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод `fit` этого класса находит все уникальные значения и строит таблицу для соответствия каждой категории некоторому числу, а метод `transform` непосредственно преобразует значения в числа. После `fit` у `label_encoder` будет доступно поле `classes_`, содержащее все уникальные значения. Пронумеруем их, чтобы убедиться, что преобразование выполнено верно. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'basic.4y', 1: 'basic.6y', 2: 'basic.9y', 3: 'high.school', 4: 'illiterate', 5: 'professional.course', 6: 'university.degree', 7: 'unknown'}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWkAAAD3CAYAAADfYKXJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADctJREFUeJzt3X2IZfV9x/H3rLu60Y6JkOsTtVpo820biEKlMT5ul4om\nZN00pC2EWB+I1tISW5boKlpI0T66JWlTyeNkTdIQSKzZrGCyYLWpFhvyUNjQ+l1MUyikodutD2s0\nmt2d/nHObC7jzt7j3XNmvru8X7Aw5zL+5sM493N/9/c795yZ+fl5JEk1rVrpAJKkpVnSklSYJS1J\nhVnSklSYJS1Jha3ue8B9+/bPP/30C30P24tTTjkRs02ncj6zTcds0xsi32g0O3Oox3ufSa9efVzf\nQ/bGbNOrnM9s0zHb9JYzn8sdklSYJS1JhVnSklSYJS1JhVnSklSYJS1JhVnSklSYJS1JhVnSklRY\np4+FR8SpwDeByzPzyWEjSZIWTJxJR8Qa4KPAi8PHkSSN67LccQ/wEeD7A2eRJC0yc7h7HEbEtcBP\nZ+ZdEfEocFOH5Q5vmihJr94hr4I3qaS/RlO688B5wC7gqsz8wWF+0Pzu3XuPIOdwRqNZzDadyvnM\nNh2zTW+IfEtdqvSwG4eZeenC12Mz6cMVtCSpR56CJ0mFdb4zS2auGzCHJOkQnElLUmGWtCQVZklL\nUmGWtCQVZklLUmGWtCQVZklLUmGWtCQVZklLUmGWtCQVZklLUmGWtCQVZklLUmGWtCQVZklLUmGd\nryfd1YZN2/oecnBzm9evdARJOiRn0pJUmCUtSYVZ0pJU2MQ16Yi4Fri2PVwLnAecnpnPDBdLkgQd\nSjoztwJbASLib4E5C1qSlkfn5Y6IOB94Y2Z+bMA8kqQxr+YUvNuBDwwVZCWNRrMrHQGok2MplfOZ\nbTpmm95y5etU0hHxOiAy85GB86yI3bv3rnQERqPZEjmWUjmf2aZjtukNkW+p0u+63HEp8HBvaSRJ\nnXQt6QD+Y8ggkqRX6rTckZl/OXQQSdIr+WEWSSrMkpakwnq/Ct72LRvL7spW3zGWpMWcSUtSYZa0\nJBVmSUtSYZa0JBVmSUtSYZa0JBVmSUtSYZa0JBVmSUtSYZa0JBVmSUtSYZa0JBVmSUtSYb1fBW/D\npm19D1na3Ob1Kx1B0jHMmbQkFWZJS1JhlrQkFdappCPizRHx6MBZJEmLTNw4jIhbgKuBHw4fR5I0\nrsvZHd8F3gl8ZuAsR6XRaLbkWEOonM9s0zHb9JYr38SSzsz7I+KcZchyVOrrxrbVb5JbOZ/ZpmO2\n6Q2Rb6nSd+NQkgqzpCWpMEtakgrr9LHwzPxP4IJho0iSFnMmLUmF9X6Bpe1bNpbdla2+YyxJizmT\nlqTCLGlJKsySlqTCLGlJKsySlqTCLGlJKsySlqTCLGlJKsySlqTCLGlJKsySlqTCLGlJKsySlqTC\ner8K3oZN2/oeUgOb27x+pSNIWoIzaUkqzJKWpMIsaUkqbOKadESsAu4FzgVeAt6bmU8NHUyS1G0m\n/Q5gbWa+BdgMbBk2kiRpQZezOy4GvgKQmU9ExPnDRtJyG41me/2+lWC26ZhtesuVr0tJnww8O3a8\nPyJWZ+a+gTJpmXW5OW/lm/iabTpmm94Q+ZYq/S7LHc8B4//1KgtakpZHl5J+HHgbQERcAOwcNJEk\n6aAuyx0PAJdHxD8DM8B1w0aSJC2YWNKZeQC4aRmySJIW8cMsklRY7xdY2r5lY9ld2co7xpWzSVo5\nzqQlqTBLWpIKs6QlqTBLWpIKs6QlqTBLWpIKs6QlqTBLWpIKs6QlqTBLWpIKs6QlqTBLWpIKs6Ql\nqbDer4K3YdO2vofUMWZu8/qVjiAdNZxJS1JhlrQkFWZJS1JhndakI+JbwHPt4fcy05vRStIymFjS\nEbEWmMnMdcPHkSSN6zKTPhc4MSJ2tN9/e2Y+MWwsSRJ0K+kXgHuATwA/DzwUEZGZ+wZNpmPWaDR7\nVIzZF7NNp3I2WL58XUp6F/BUZs4DuyJiD3AG8F+DJtMxq++7ole+07rZplM5GwyTb6nS73J2x/XA\nFoCIOBM4Gfjv3pJJkpbUZSb9SWBrRDwGzAPXu9QhSctjYkln5svAu5chiyRpET/MIkmF9X6Bpe1b\nNpZd8K+8GVE5G9TPJx2rnElLUmGWtCQVZklLUmGWtCQVZklLUmGWtCQVZklLUmGWtCQVZklLUmGW\ntCQVZklLUmGWtCQVZklLUmG9XwVvw6ZtfQ8pdTK3ef1KR5B650xakgqzpCWpMEtakgo77Jp0RKwB\n5oBzgBOAuzLzy8uQS5LE5Jn0e4A9mXkJcCXw4eEjSZIWTDq74wvAF9uvZ4B9w8aRJI07bEln5vMA\nETFLU9Z3LEcoaRqj0exKRzikqrnAbEdiufJNPE86Is4CHgDuzczPDR9Jmk7Fu5lXvsu62aY3RL6l\nSn/SxuFpwA7g9zPz4V4TSZImmjSTvh04BbgzIu5sH3trZr44bCxJEkxek74ZuHmZskiSFvHDLJJU\nmCUtSYX1fhW87Vs2lt2VrbxjXDkb1M5XOZt0pJxJS1JhlrQkFWZJS1JhlrQkFWZJS1JhlrQkFWZJ\nS1JhlrQkFWZJS1JhlrQkFWZJS1JhlrQkFdb7BZY2bNrW95CSiprbvH6lIxzznElLUmGWtCQVZklL\nUmET16Qj4jjg40AA88BNmfmdoYNJkrrNpDcAZOZFwB3A3YMmkiQdNLGkM/NLwI3t4dnAM4MmkiQd\n1OkUvMzcFxH3Ab8OvGvYSJKOFqPR7FE5dh+WK1/n86Qz85qIuBX4l4j4pcz84YC5JB0FhroBcPWb\nCw+Rb6nSn7jcERFXR8Rt7eELwIH2nyRpYF1m0n8PfCoivgasAf4gM18cNpYkCTqUdLus8ZvLkEWS\ntIgfZpGkwixpSSqs96vgbd+yseyubOUd48rZoHY+s02ncjb9hDNpSSrMkpakwixpSSrMkpakwixp\nSSrMkpakwixpSSrMkpakwixpSSrMkpakwixpSSrMkpakwnq/wNKGTdv6HlKSypvbvH6QcZ1JS1Jh\nlrQkFWZJS1JhlrQkFdZp4zAibgOuAo4H7s3MTw6aSpIEdJhJR8Q64ELgIuAy4KyBM0mSWl1m0lcA\nO4EHgJOB9w+aSJKOQqPR7CDjdinp1wNnA28Hfhb4ckT8QmbOD5JIko5CR3pT36VKvktJ7wGezMyX\ngYyIHwEj4H+OKJEkaaIuZ3c8BlwZETMRcSZwEk1xS5IGNrGkM/NB4NvA14HtwO9l5v6hg0mSOp6C\nl5m3DB1EkvRKfphFkgqbmZ/v/SSN+SPd5RzKaDR7xDuwQ6mcDWrnM9t0zDa9IfKNRrMzh3rcmbQk\nFWZJS1JhlrQkFWZJS1JhlrQkFWZJS1JhQ5yCJ0nqiTNpSSrMkpakwixpSSrMkpakwixpSSrMkpak\nwixpSSqs00X/J4mIVcC9wLnAS8B7M/OpPsZ+FRneDPx5Zq6LiJ8DtgLzwHdo7iZzICJuAH4H2Afc\nlZkPRsRrgM8CpwJ7gWsyc3dPmdYAc8A5wAnAXcC/VcjW5jsO+DgQbZ6bgB9VyddmPBX4JnB5+7NL\nZIuIbwHPtYffA+4ulO024CrgeJrn5T8WynYtcG17uBY4D7gY+OBK52ufr/fRPF/3AzdQ4G+ur5n0\nO4C1mfkWYDOwpadxO4mIW4BP0PxPB/gr4I7MvASYATZGxOnA+4CLgCuAP42IE4DfBXa23/tp4I4e\no70H2NOOfSXw4ULZADYAZOZF7dh3V8rXPmk+CrzYPlQiW0SsBWYyc13777pC2dYBF7Y/8zLgrCrZ\nADJz68LvjebF933AHxXJ9zZgdWZeCPwxRZ4PfZX0xcBXADLzCeD8nsbt6rvAO8eOf5lm9gDwEPBr\nwK8Aj2fmS5n5LPAU8CbGso99b1++ANzZfj1D86pbJRuZ+SXgxvbwbOCZSvmAe4CPAN9vj6tkOxc4\nMSJ2RMQ/RMQFhbJdAewEHqC5J+mDhbIdFBHnA2/MzI8VyrcLWN2uDJwM/LhCtr5K+mTg2bHj/RHR\ny1JKF5l5P80vdMFMZi583n0v8FpemfFQjy881leu5zNzb0TMAl+keWUtkW0s476IuA/4G+DvquRr\n3xbvzsyvjj1cIhvwAs0LyBU0S0Rlfm/A62kmSb8xlm1VkWzjbgc+0H5d5Xf3PM1Sx5M0y4B/XSFb\nXyX9HDA7Pm5m7utp7GkcGPt6lmaGuDjjoR5feKw3EXEW8Ajwmcz8XKVsCzLzGuANNH+YrymS73rg\n8oh4lGbd8tM0a30Vsu0CPpuZ85m5C9gDnFYk2x7gq5n5cmYmzR7DeFms+N9cRLwOiMx8pH2oynPi\nD2l+d2+gebd0H826/opm66ukH6dZz6F967ezp3Gn9e12bQ7grcA/AV8HLomItRHxWuAXaTYCDmYf\n+95eRMRpwA7g1sycq5StzXd1u8kEzezwAPCNCvky89LMvKxdu/xX4LeBhypko3kB2QIQEWfSzKB2\nFMn2GHBlRMy02U4CHi6SbcGlwMNjx1WeE0/zk5nw/wFrKmTr5Sp4Y2d3vIlm7fW6zHzyiAd+dRnO\nAT6fmRdExMKs8Hjg34EbMnN/uyN7I82L059k5v0RcSLNK+YZwMvAuzPzBz1l+hDwWzRvnxbcTPM2\nakWztflOAj4FnE7zB/lnbaYV/90tyvkozVv3AxWyRcTxNDv+P0Oz638r8L8VsrX5/gL41fZn3k5z\n9kmJbG2+9wM/zswPtsdVnq8/RXM21hltlg8B31jpbF6qVJIK88MsklSYJS1JhVnSklSYJS1JhVnS\nklSYJS1JhVnSklTY/wPKntPK5hCTQgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113bc2940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mapped_education = pd.Series(label_encoder.fit_transform(df['education']))\n",
    "mapped_education.value_counts().plot.barh()\n",
    "print(dict(enumerate(label_encoder.classes_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что произойдет, если у нас появятся данные с другими категориями?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: y contains new labels: ['high_school']\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    label_encoder.transform(df['education'].replace('high.school', 'high_school'))\n",
    "except Exception as e:\n",
    "    print('Error:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, при использовании этого подхода мы всегда должны быть уверены, что признак не может принимать неизвестных ранее значений. К этой проблеме мы вернемся чуть позже, а сейчас заменим весь столбец education на преобразованный:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>student</td>\n",
       "      <td>single</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>jun</td>\n",
       "      <td>mon</td>\n",
       "      <td>901</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>94.465</td>\n",
       "      <td>-41.8</td>\n",
       "      <td>4.961</td>\n",
       "      <td>5228.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>6</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>aug</td>\n",
       "      <td>tue</td>\n",
       "      <td>208</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.444</td>\n",
       "      <td>-36.1</td>\n",
       "      <td>4.963</td>\n",
       "      <td>5228.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>jun</td>\n",
       "      <td>tue</td>\n",
       "      <td>131</td>\n",
       "      <td>5</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.4</td>\n",
       "      <td>94.465</td>\n",
       "      <td>-41.8</td>\n",
       "      <td>4.864</td>\n",
       "      <td>5228.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>technician</td>\n",
       "      <td>married</td>\n",
       "      <td>6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jul</td>\n",
       "      <td>tue</td>\n",
       "      <td>404</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>92.469</td>\n",
       "      <td>-33.6</td>\n",
       "      <td>1.044</td>\n",
       "      <td>5076.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>6</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>nov</td>\n",
       "      <td>mon</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>93.200</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>4.191</td>\n",
       "      <td>5195.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          job  marital  education  default housing loan    contact  \\\n",
       "0   26      student   single          3       no      no   no  telephone   \n",
       "1   46       admin.  married          6       no     yes   no   cellular   \n",
       "2   49  blue-collar  married          0  unknown     yes  yes  telephone   \n",
       "3   31   technician  married          6       no      no   no   cellular   \n",
       "4   42    housemaid  married          6       no     yes   no  telephone   \n",
       "\n",
       "  month day_of_week  duration  campaign  pdays  previous     poutcome  \\\n",
       "0   jun         mon       901         1    999         0  nonexistent   \n",
       "1   aug         tue       208         2    999         0  nonexistent   \n",
       "2   jun         tue       131         5    999         0  nonexistent   \n",
       "3   jul         tue       404         1    999         0  nonexistent   \n",
       "4   nov         mon        85         1    999         0  nonexistent   \n",
       "\n",
       "   emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  nr.employed  \n",
       "0           1.4          94.465          -41.8      4.961       5228.1  \n",
       "1           1.4          93.444          -36.1      4.963       5228.1  \n",
       "2           1.4          94.465          -41.8      4.864       5228.1  \n",
       "3          -2.9          92.469          -33.6      1.044       5076.2  \n",
       "4          -0.1          93.200          -42.0      4.191       5195.8  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['education'] = mapped_education\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Продолжим преобразование для всех столбцов, имеющих тип `object` – именно этот тип задается в pandas для таких данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>901</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>94.465</td>\n",
       "      <td>-41.8</td>\n",
       "      <td>4.961</td>\n",
       "      <td>5228.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>208</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>93.444</td>\n",
       "      <td>-36.1</td>\n",
       "      <td>4.963</td>\n",
       "      <td>5228.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>131</td>\n",
       "      <td>5</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>94.465</td>\n",
       "      <td>-41.8</td>\n",
       "      <td>4.864</td>\n",
       "      <td>5228.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>404</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>92.469</td>\n",
       "      <td>-33.6</td>\n",
       "      <td>1.044</td>\n",
       "      <td>5076.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>93.200</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>4.191</td>\n",
       "      <td>5195.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  job  marital  education  default  housing  loan  contact  month  \\\n",
       "0   26    8        2          3        0        0     0        1      4   \n",
       "1   46    0        1          6        0        2     0        0      1   \n",
       "2   49    1        1          0        1        2     2        1      4   \n",
       "3   31    9        1          6        0        0     0        0      3   \n",
       "4   42    3        1          6        0        2     0        1      7   \n",
       "\n",
       "   day_of_week  duration  campaign  pdays  previous  poutcome  emp.var.rate  \\\n",
       "0            1       901         1    999         0         1           1.4   \n",
       "1            3       208         2    999         0         1           1.4   \n",
       "2            3       131         5    999         0         1           1.4   \n",
       "3            3       404         1    999         0         1          -2.9   \n",
       "4            1        85         1    999         0         1          -0.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed  \n",
       "0          94.465          -41.8      4.961       5228.1  \n",
       "1          93.444          -36.1      4.963       5228.1  \n",
       "2          94.465          -41.8      4.864       5228.1  \n",
       "3          92.469          -33.6      1.044       5076.2  \n",
       "4          93.200          -42.0      4.191       5195.8  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns = df.columns[df.dtypes == 'object'].union(['education'])\n",
    "for column in categorical_columns:\n",
    "    df[column] = label_encoder.fit_transform(df[column])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основная проблема такого представления заключается в том, что числовой код создал евклидово представление для данных.\n",
    "\n",
    "К примеру, нами неявным образом была введена алгебра над значениями работы - мы можем вычесть работу клиента 1 из работы клиента 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1].job - df.loc[2].job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Конечно же, эта операция не имеет никакого смысла. Но именно на этом основаны метрики близости объектов, что делает бессмысленным применение метода ближайшего соседа на данных в таком виде. Аналогичным образом, никакого смысла не будет иметь применение линейных моделей. Убедимся в этом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      1.00      0.94      6096\n",
      "          1       0.00      0.00      0.00       803\n",
      "\n",
      "avg / total       0.78      0.88      0.83      6899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def logistic_regression_accuracy_on(dataframe, labels):\n",
    "    features = dataframe.as_matrix()\n",
    "    train_features, test_features, train_labels, test_labels = \\\n",
    "        train_test_split(features, labels)\n",
    "\n",
    "    logit = LogisticRegression()\n",
    "    logit.fit(train_features, train_labels)\n",
    "    return classification_report(test_labels, logit.predict(test_features))\n",
    "\n",
    "print(logistic_regression_accuracy_on(df[categorical_columns], labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы мы смогли применять линейные модели на таких данных нам необходим другой метод, который называется One-Hot Encoding\n",
    "\n",
    "## One-Hot Encoding\n",
    "\n",
    "Предположим, что некоторый признак может принимать 10 разных значений. В этом случае one hot encoding подразумевает создание 10 признаков, все из которых равны нулю *за исключением одного*. На позицию, соответствующую численному значению признака мы помещаем 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6  7  8  9\n",
       "0  0  0  0  0  0  0  1  0  0  0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_example = pd.DataFrame([{i: 0 for i in range(10)}])\n",
    "one_hot_example.loc[0, 6] = 1\n",
    "one_hot_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эта техника реализована в `sklearn.preprocessing` в классе `OneHotEncoder`. По умолчанию `OneHotEncoder` преобразует данные в разреженную матрицу, чтобы не расходовать память на хранение многочисленных нулей. Однако в этом примере размер данных не является для нас проблемой, поэтому мы будем использовать \"плотное\" представление."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "onehot_encoder = OneHotEncoder(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4    5    6    7    8    9  ...    43   44   45   46  \\\n",
       "0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  1.0  0.0  0.0   \n",
       "1  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "2  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0 ...   0.0  1.0  0.0  0.0   \n",
       "3  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0 ...   1.0  0.0  0.0  0.0   \n",
       "4  0.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "\n",
       "    47   48   49   50   51   52  \n",
       "0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "4  1.0  0.0  0.0  0.0  1.0  0.0  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_categorical_columns = pd.DataFrame(onehot_encoder.fit_transform(df[categorical_columns]))\n",
    "encoded_categorical_columns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы получили 53 столбца - именно столько различных уникальных значений могут принимать категориальные столбцы исходной выборки. Преобразованные с помощью One-Hot Encoding данные начинают обретать смысл для линейной модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.99      0.94      6100\n",
      "          1       0.65      0.20      0.30       799\n",
      "\n",
      "avg / total       0.87      0.89      0.87      6899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(logistic_regression_accuracy_on(encoded_categorical_columns, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Хэширование признаков (Hashing trick)\n",
    "Реальные данные могут оказаться гораздо более динамичными, и мы не всегда можем рассчитывать, что категориальные признаки не будут принимать новых значений. Все это сильно затрудняет использование уже обученных моделей на новых данных. Кроме того, `LabelEncoder` подразумевает предварительный анализ всей выборки и хранение построенных отображений в памяти, что затрудняет работу в режиме больших данных.\n",
    "\n",
    "Для решения этих проблем существует более простой подход к векторизации категориальных признаков, основанный на хэшировании, известный как hashing trick. \n",
    "\n",
    "Хэш-функции могут помочь нам в задаче поиска уникальных кодов для различных значений признака, к примеру:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "university.degree -> 5881601602355107917\n",
      "high.school -> 2898571036245604533\n",
      "illiterate -> -6295611900574865302\n"
     ]
    }
   ],
   "source": [
    "for s in ('university.degree', 'high.school', 'illiterate'):\n",
    "    print(s, '->', hash(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отрицательные и настолько большие по модулю значения нам не подойдут. Ограничим область значений хэш-функции:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "university.degree -> 17\n",
      "high.school -> 8\n",
      "illiterate -> 23\n"
     ]
    }
   ],
   "source": [
    "hash_space = 25\n",
    "for s in ('university.degree', 'high.school', 'illiterate'):\n",
    "    print(s, '->', hash(s) % hash_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Представим, что у нас в выборке есть холостой студент, которому позвонили в понедельник, тогда его вектор признаков будет сформирован аналогично One-Hot Encoding, но в едином пространстве фиксированного размера для всех признаков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job=student -> 24\n",
      "marital=single -> 22\n",
      "day_of_week=mon -> 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4    5    6    7    8    9  ...    15   16   17   18  \\\n",
       "0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "\n",
       "    19   20   21   22   23   24  \n",
       "0  0.0  0.0  0.0  1.0  0.0  1.0  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashing_example = pd.DataFrame([{i: 0.0 for i in range(hash_space)}])\n",
    "for s in ('job=student', 'marital=single', 'day_of_week=mon'):\n",
    "    print(s, '->', hash(s) % hash_space)\n",
    "    hashing_example.loc[0, hash(s) % hash_space] = 1\n",
    "hashing_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стоит обратить внимание, что в этом примере хэшировались не только значения признаков, а пары **название признака + значение признака**. Это необходимо, чтобы разделить одинаковые значения разных признаков между собой, к примеру:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert hash('no') == hash('no')\n",
    "assert hash('housing=no') != hash('loan=no')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Может ли произойти коллизия хэш-функции, то есть совпадение кодов для двух разных значений? Нетрудно доказать, что при достаточном размере пространства хэширования это происходит редко, но даже в тех случаях, когда это происходит, это не будет приводить к существенному ухудшению качества классификации или регрессии.\n",
    "\n",
    "Возможно, вы спросите: \"а что за хрень вообще происходит?\", и покажется, что при хэшировании признаков страдает здравый смысл. Возможно, но эта эвристика – по сути, единственный подход к тому, чтобы работать с категориальными признаками, у которых много уникальных значений. Более того, эта техника себя хорошо зарекомендовала по результатами на практике. Подробней про хэширование признаков (learning to hash) можно почитать в [этом](https://arxiv.org/abs/1509.05472) обзоре, а также в [материалах](https://github.com/esokolov/ml-course-hse/blob/master/2016-fall/lecture-notes/lecture06-linclass.pdf) Евгения Соколова."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Библиотека Vowpal Wabbit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vowpal Wabbit (VW) является одной из наиболее широко используемых библиотек в индустрии. Её отличает высокая скорость работы и поддержка большого количества различных режимов обучения. Особый интерес для больших и высокоразмерных данных представляет онлайн-обучение  – самая сильная сторона библиотеки. \n",
    "Также реализовано хэширование признаков, и Vowpal Wabbit отлично подходит для работы с текстовыми данными.\n",
    "\n",
    "Основным интерфейсом для работы с VW является shell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "VW options:\n",
      "  --random_seed arg                     seed random number generator\n",
      "  --ring_size arg                       size of example ring\n",
      "\n",
      "Update options:\n",
      "  -l [ --learning_rate ] arg            Set learning rate\n",
      "  --power_t arg                         t power value\n",
      "  --decay_learning_rate arg             Set Decay factor for learning_rate \n",
      "                                        between passes\n",
      "  --initial_t arg                       initial t value\n",
      "  --feature_mask arg                    Use existing regressor to determine \n",
      "                                        which parameters may be updated.  If no\n",
      "                                        initial_regressor given, also used for \n",
      "                                        initial weights.\n",
      "\n",
      "Weight options:\n",
      "  -i [ --initial_regressor ] arg        Initial regressor(s)\n",
      "  --initial_weight arg                  Set all weights to an initial value of \n",
      "                                        arg.\n",
      "  --random_weights arg                  make initial weights random\n",
      "  --normal_weights arg                  make initial weights normal\n",
      "  --truncated_normal_weights arg        make initial weights truncated normal\n",
      "  --sparse_weights                      Use a sparse datastructure for weights\n",
      "  --input_feature_regularizer arg       Per feature regularization input file\n",
      "\n",
      "Parallelization options:\n",
      "  --span_server arg                     Location of server for setting up \n",
      "                                        spanning tree\n",
      "  --threads                             Enable multi-threading\n",
      "  --unique_id arg (=0)                  unique id used for cluster parallel \n",
      "                                        jobs\n",
      "  --total arg (=1)                      total number of nodes used in cluster \n",
      "                                        parallel job\n",
      "  --node arg (=0)                       node number in cluster parallel job\n",
      "\n",
      "Diagnostic options:\n",
      "  --version                             Version information\n",
      "  -a [ --audit ]                        print weights of features\n",
      "  -P [ --progress ] arg                 Progress update frequency. int: \n",
      "                                        additive, float: multiplicative\n",
      "  --quiet                               Don't output disgnostics and progress \n",
      "                                        updates\n",
      "  -h [ --help ]                         Look here: http://hunch.net/~vw/ and \n",
      "                                        click on Tutorial.\n",
      "\n",
      "Feature options:\n",
      "  --hash arg                            how to hash the features. Available \n",
      "                                        options: strings, all\n",
      "  --ignore arg                          ignore namespaces beginning with \n",
      "                                        character <arg>\n",
      "  --ignore_linear arg                   ignore namespaces beginning with \n",
      "                                        character <arg> for linear terms only\n",
      "  --keep arg                            keep namespaces beginning with \n",
      "                                        character <arg>\n",
      "  --redefine arg                        redefine namespaces beginning with \n",
      "                                        characters of string S as namespace N. \n",
      "                                        <arg> shall be in form 'N:=S' where := \n",
      "                                        is operator. Empty N or S are treated \n",
      "                                        as default namespace. Use ':' as a \n",
      "                                        wildcard in S.\n",
      "  -b [ --bit_precision ] arg            number of bits in the feature table\n",
      "  --noconstant                          Don't add a constant feature\n",
      "  -C [ --constant ] arg                 Set initial value of constant\n",
      "  --ngram arg                           Generate N grams. To generate N grams \n",
      "                                        for a single namespace 'foo', arg \n",
      "                                        should be fN.\n",
      "  --skips arg                           Generate skips in N grams. This in \n",
      "                                        conjunction with the ngram tag can be \n",
      "                                        used to generate generalized \n",
      "                                        n-skip-k-gram. To generate n-skips for \n",
      "                                        a single namespace 'foo', arg should be\n",
      "                                        fN.\n",
      "  --feature_limit arg                   limit to N features. To apply to a \n",
      "                                        single namespace 'foo', arg should be \n",
      "                                        fN\n",
      "  --affix arg                           generate prefixes/suffixes of features;\n",
      "                                        argument '+2a,-3b,+1' means generate \n",
      "                                        2-char prefixes for namespace a, 3-char\n",
      "                                        suffixes for b and 1 char prefixes for \n",
      "                                        default namespace\n",
      "  --spelling arg                        compute spelling features for a give \n",
      "                                        namespace (use '_' for default \n",
      "                                        namespace)\n",
      "  --dictionary arg                      read a dictionary for additional \n",
      "                                        features (arg either 'x:file' or just \n",
      "                                        'file')\n",
      "  --dictionary_path arg                 look in this directory for \n",
      "                                        dictionaries; defaults to current \n",
      "                                        directory or env{PATH}\n",
      "  --interactions arg                    Create feature interactions of any \n",
      "                                        level between namespaces.\n",
      "  --permutations                        Use permutations instead of \n",
      "                                        combinations for feature interactions \n",
      "                                        of same namespace.\n",
      "  --leave_duplicate_interactions        Don't remove interactions with \n",
      "                                        duplicate combinations of namespaces. \n",
      "                                        For ex. this is a duplicate: '-q ab -q \n",
      "                                        ba' and a lot more in '-q ::'.\n",
      "  -q [ --quadratic ] arg                Create and use quadratic features\n",
      "  --q: arg                              : corresponds to a wildcard for all \n",
      "                                        printable characters\n",
      "  --cubic arg                           Create and use cubic features\n",
      "\n",
      "Example options:\n",
      "  -t [ --testonly ]                     Ignore label information and just test\n",
      "  --holdout_off                         no holdout data in multiple passes\n",
      "  --holdout_period arg                  holdout period for test only, default \n",
      "                                        10\n",
      "  --holdout_after arg                   holdout after n training examples, \n",
      "                                        default off (disables holdout_period)\n",
      "  --early_terminate arg                 Specify the number of passes tolerated \n",
      "                                        when holdout loss doesn't decrease \n",
      "                                        before early termination, default is 3\n",
      "  --passes arg                          Number of Training Passes\n",
      "  --initial_pass_length arg             initial number of examples per pass\n",
      "  --examples arg                        number of examples to parse\n",
      "  --min_prediction arg                  Smallest prediction to output\n",
      "  --max_prediction arg                  Largest prediction to output\n",
      "  --sort_features                       turn this on to disregard order in \n",
      "                                        which features have been defined. This \n",
      "                                        will lead to smaller cache sizes\n",
      "  --loss_function arg (=squared)        Specify the loss function to be used, \n",
      "                                        uses squared by default. Currently \n",
      "                                        available ones are squared, classic, \n",
      "                                        hinge, logistic, quantile and poisson.\n",
      "  --quantile_tau arg (=0.5)             Parameter \\tau associated with Quantile\n",
      "                                        loss. Defaults to 0.5\n",
      "  --l1 arg                              l_1 lambda\n",
      "  --l2 arg                              l_2 lambda\n",
      "  --no_bias_regularization arg          no bias in regularization\n",
      "  --named_labels arg                    use names for labels (multiclass, etc.)\n",
      "                                        rather than integers, argument \n",
      "                                        specified all possible labels, \n",
      "                                        comma-sep, eg \"--named_labels \n",
      "                                        Noun,Verb,Adj,Punc\"\n",
      "\n",
      "Output model:\n",
      "  -f [ --final_regressor ] arg          Final regressor\n",
      "  --readable_model arg                  Output human-readable final regressor \n",
      "                                        with numeric features\n",
      "  --invert_hash arg                     Output human-readable final regressor \n",
      "                                        with feature names.  Computationally \n",
      "                                        expensive.\n",
      "  --save_resume                         save extra state so learning can be \n",
      "                                        resumed later with new data\n",
      "  --preserve_performance_counters       reset performance counters when \n",
      "                                        warmstarting\n",
      "  --save_per_pass                       Save the model after every pass over \n",
      "                                        data\n",
      "  --output_feature_regularizer_binary arg\n",
      "                                        Per feature regularization output file\n",
      "  --output_feature_regularizer_text arg Per feature regularization output file,\n",
      "                                        in text\n",
      "  --id arg                              User supplied ID embedded into the \n",
      "                                        final regressor\n",
      "\n",
      "Output options:\n",
      "  -p [ --predictions ] arg              File to output predictions to\n",
      "  -r [ --raw_predictions ] arg          File to output unnormalized predictions\n",
      "                                        to\n",
      "\n",
      "Reduction options, use [option] --help for more info:\n",
      "\n",
      "  --audit_regressor arg                 stores feature names and their \n",
      "                                        regressor values. Same dataset must be \n",
      "                                        used for both regressor training and \n",
      "                                        this mode.\n",
      "\n",
      "  --bootstrap arg                       k-way bootstrap by online importance \n",
      "                                        resampling\n",
      "\n",
      "  --search arg                          Use learning to search, \n",
      "                                        argument=maximum action id or 0 for LDF\n",
      "\n",
      "  --replay_c arg                        use experience replay at a specified \n",
      "                                        level [b=classification/regression, \n",
      "                                        m=multiclass, c=cost sensitive] with \n",
      "                                        specified buffer size\n",
      "\n",
      "  --explore_eval                        Evaluate explore_eval adf policies\n",
      "\n",
      "  --cbify arg                           Convert multiclass on <k> classes into \n",
      "                                        a contextual bandit problem\n",
      "\n",
      "  --cb_explore_adf                      Online explore-exploit for a contextual\n",
      "                                        bandit problem with multiline action \n",
      "                                        dependent features\n",
      "\n",
      "  --cb_explore arg                      Online explore-exploit for a <k> action\n",
      "                                        contextual bandit problem\n",
      "\n",
      "  --multiworld_test arg                 Evaluate features as a policies\n",
      "\n",
      "  --cb_adf                              Do Contextual Bandit learning with \n",
      "                                        multiline action dependent features.\n",
      "\n",
      "  --cb arg                              Use contextual bandit learning with <k>\n",
      "                                        costs\n",
      "\n",
      "  --csoaa_ldf arg                       Use one-against-all multiclass learning\n",
      "                                        with label dependent features.  Specify\n",
      "                                        singleline or multiline.\n",
      "\n",
      "  --wap_ldf arg                         Use weighted all-pairs multiclass \n",
      "                                        learning with label dependent features.\n",
      "                                          Specify singleline or multiline.\n",
      "\n",
      "  --interact arg                        Put weights on feature products from \n",
      "                                        namespaces <n1> and <n2>\n",
      "\n",
      "  --csoaa arg                           One-against-all multiclass with <k> \n",
      "                                        costs\n",
      "\n",
      "  --multilabel_oaa arg                  One-against-all multilabel with <k> \n",
      "                                        labels\n",
      "\n",
      "  --classweight arg\n",
      "\n",
      "  --recall_tree arg                     Use online tree for multiclass\n",
      "\n",
      "  --log_multi arg                       Use online tree for multiclass\n",
      "\n",
      "  --ect arg                             Error correcting tournament with <k> \n",
      "                                        labels\n",
      "\n",
      "  --boosting arg                        Online boosting with <N> weak learners\n",
      "\n",
      "  --oaa arg                             One-against-all multiclass with <k> \n",
      "                                        labels\n",
      "\n",
      "  --top arg                             top k recommendation\n",
      "\n",
      "  --replay_m arg                        use experience replay at a specified \n",
      "                                        level [b=classification/regression, \n",
      "                                        m=multiclass, c=cost sensitive] with \n",
      "                                        specified buffer size\n",
      "\n",
      "  --binary                              report loss as binary classification on\n",
      "                                        -1,1\n",
      "\n",
      "  --link arg (=identity)                Specify the link function: identity, \n",
      "                                        logistic, glf1 or poisson\n",
      "\n",
      "  --stage_poly                          use stagewise polynomial feature \n",
      "                                        learning\n",
      "\n",
      "  --lrqfa arg                           use low rank quadratic features with \n",
      "                                        field aware weights\n",
      "\n",
      "  --lrq arg                             use low rank quadratic features\n",
      "\n",
      "  --autolink arg                        create link function with polynomial d\n",
      "\n",
      "  --marginal arg                        substitute marginal label estimates for\n",
      "                                        ids\n",
      "\n",
      "  --new_mf arg                          rank for reduction-based matrix \n",
      "                                        factorization\n",
      "\n",
      "  --nn arg                              Sigmoidal feedforward network with <k> \n",
      "                                        hidden units\n",
      "\n",
      "confidence options:\n",
      "  --confidence_after_training           Confidence after training\n",
      "\n",
      "  --confidence                          Get confidence for binary predictions\n",
      "\n",
      "  --active_cover                        enable active learning with cover\n",
      "\n",
      "  --active                              enable active learning\n",
      "\n",
      "  --replay_b arg                        use experience replay at a specified \n",
      "                                        level [b=classification/regression, \n",
      "                                        m=multiclass, c=cost sensitive] with \n",
      "                                        specified buffer size\n",
      "\n",
      "  --baseline                            Learn an additive baseline (from \n",
      "                                        constant features) and a residual \n",
      "                                        separately in regression.\n",
      "\n",
      "  --OjaNewton                           Online Newton with Oja's Sketch\n",
      "\n",
      "  --bfgs                                use bfgs optimization\n",
      "\n",
      "  --conjugate_gradient                  use conjugate gradient based \n",
      "                                        optimization\n",
      "\n",
      "  --lda arg                             Run lda with <int> topics\n",
      "\n",
      "  --noop                                do no learning\n",
      "\n",
      "  --print                               print examples\n",
      "\n",
      "  --rank arg                            rank for matrix factorization.\n",
      "\n",
      "  --sendto arg                          send examples to <host>\n",
      "\n",
      "  --svrg                                Streaming Stochastic Variance Reduced \n",
      "                                        Gradient\n",
      "\n",
      "  --ftrl                                FTRL: Follow the Proximal Regularized \n",
      "                                        Leader\n",
      "\n",
      "  --pistol                              FTRL: Parameter-free Stochastic \n",
      "                                        Learning\n",
      "\n",
      "  --ksvm                                kernel svm\n",
      "\n",
      "Gradient Descent options:\n",
      "  --sgd                                 use regular stochastic gradient descent\n",
      "                                        update.\n",
      "  --adaptive                            use adaptive, individual learning \n",
      "                                        rates.\n",
      "  --invariant                           use safe/importance aware updates.\n",
      "  --normalized                          use per feature normalized updates\n",
      "  --sparse_l2 arg (=0)                  use per feature normalized updates\n",
      "\n",
      "Input options:\n",
      "  -d [ --data ] arg                     Example Set\n",
      "  --daemon                              persistent daemon mode on port 26542\n",
      "  --foreground                          in persistent daemon mode, do not run \n",
      "                                        in the background\n",
      "  --port arg                            port to listen on; use 0 to pick unused\n",
      "                                        port\n",
      "  --num_children arg                    number of children for persistent \n",
      "                                        daemon mode\n",
      "  --pid_file arg                        Write pid file in persistent daemon \n",
      "                                        mode\n",
      "  --port_file arg                       Write port used in persistent daemon \n",
      "                                        mode\n",
      "  -c [ --cache ]                        Use a cache.  The default is \n",
      "                                        <data>.cache\n",
      "  --cache_file arg                      The location(s) of cache_file.\n",
      "  --json                                Enable JSON parsing.\n",
      "  --dsjson                              Enable Decision Service JSON parsing.\n",
      "  -k [ --kill_cache ]                   do not reuse existing cache: create a \n",
      "                                        new one always\n",
      "  --compressed                          use gzip format whenever possible. If a\n",
      "                                        cache file is being created, this \n",
      "                                        option creates a compressed cache file.\n",
      "                                        A mixture of raw-text & compressed \n",
      "                                        inputs are supported with \n",
      "                                        autodetection.\n",
      "  --no_stdin                            do not default to reading from stdin\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = \n",
      "num sources = 1\n"
     ]
    }
   ],
   "source": [
    "!vw --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Vowpal Wabbit считывает данные из файла или стандартного ввода (stdin) в формате, который имеет следующий вид:\n",
    "\n",
    "`[Label] [Importance] [Tag]|Namespace Features |Namespace Features ... |Namespace Features`\n",
    "\n",
    "`Namespace=String[:Value]`\n",
    "\n",
    "`Features=(String[:Value] )*`\n",
    "\n",
    "где [] обозначает необязательные элементы, а (...)\\* означает повтор неопределенное число раз. \n",
    "\n",
    "- **Label** является числом, \"правильным\" ответом. В случае классификации обычно принимает значение 1/-1, а в случае регрессии некоторое вещественное число\n",
    "- **Importance** является числом и отвечает за вес примера при обучении. Это позволяет бороться с проблемой несбалансированных данных, изученной нами ранее\n",
    "- **Tag** является некоторой строкой без пробелов и отвечает за некоторое \"название\" примера, которое сохраняется при предсказании ответа. Для того, чтобы отделить Tag от Importance лучше начинать Tag с символа '.\n",
    "- **Namespace** служит для создания отдельных пространств признаков. В аргументах Namespace именуются по первой букве, это нужно учитывать при выборе их названий\n",
    "- **Features** являются непосредственно признаками объекта внутри **Namespace**. Признаки по умолчанию имеют вес 1.0, но его можно переопределить, к примеру feature:0.1. \n",
    "\n",
    "\n",
    "К примеру, под такой формат подходит следующая строка:\n",
    "\n",
    "```\n",
    "1 1.0 |Subject WHAT car is this |Organization University of Maryland:0.5 College Park\n",
    "```\n",
    "\n",
    "\n",
    "чтобы убедиться в этом, запустим vw с этим обучающим примером:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/g/odsml/mlcourseopen/jupyter_russian/topic08_sgd_hashing_vowpal_wabbit\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = \n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            1            1.0   1.0000   0.0000       10\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 1\n",
      "passes used = 1\n",
      "weighted example sum = 1.000000\n",
      "weighted label sum = 1.000000\n",
      "average loss = 1.000000\n",
      "best constant = 1.000000\n",
      "best constant's loss = 0.000000\n",
      "total feature number = 10\n"
     ]
    }
   ],
   "source": [
    "! echo 1 1.0 \"|Subject WHAT car is this |Organization University of Maryland:0.5 College Park\"| vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VW является прекрасным инструментом для работы с текстовыми данными. Убедимся в этом с помощью выборки 20newsgroups, содержащей письма из 20 различных тематических рассылок.\n",
    "\n",
    "\n",
    "## Новости. Бинарная классификация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    }
   ],
   "source": [
    "newsgroups = fetch_20newsgroups('../../data/news_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups['target_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим первый текстовый документ этой коллекции:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "rec.autos\n",
      "-----\n",
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "text = newsgroups['data'][0]\n",
    "target = newsgroups['target_names'][newsgroups['target'][0]]\n",
    "\n",
    "print('-----')\n",
    "print(target)\n",
    "print('-----')\n",
    "print(text.strip())\n",
    "print('----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приведем данные к формату Vowpal Wabbit, при этом оставляя только слова не короче 3 символов. Здесь мы не выполняем многие важные в анализе текстов процедуры (стемминг и лемматизацию), но, как увидим, задача и так будет решаться хорошо."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 |text from lerxst wam umd edu where thing subject what car this nntp posting host rac3 wam umd edu organization university maryland college park lines was wondering anyone out there could enlighten this car saw the other day was door sports car looked from the late 60s early 70s was called bricklin the doors were really small addition the front bumper was separate from the rest the body this all know anyone can tellme model name engine specs years production where this car made history whatever info you have this funky looking car please mail thanks brought you your neighborhood lerxst\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_vw_format(document, label=None):\n",
    "    return str(label or '') + ' |text ' + ' '.join(re.findall('\\w{3,}', document.lower())) + '\\n'\n",
    "\n",
    "to_vw_format(text, 1 if target == 'rec.autos' else -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобьем выборку на обучающую и тестовую и запишем в файл преобразованные таким образом документы. Будем считать документ положительным, если он относится к рассылке про автомобили **rec.autos**. Так мы построим модель, отличающую письма про автомобили от остальных: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_documents = newsgroups['data']\n",
    "all_targets = [1 if newsgroups['target_names'][target] == 'rec.autos' \n",
    "               else -1 for target in newsgroups['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_documents, test_documents, train_labels, test_labels = \\\n",
    "    train_test_split(all_documents, all_targets, random_state=7)\n",
    "    \n",
    "with open('../../data/news_data/20news_train.vw', 'w', encoding='utf-8') as vw_train_data:\n",
    "    for text, target in zip(train_documents, train_labels):\n",
    "        vw_train_data.write(to_vw_format(text, target))\n",
    "with open('../../data/news_data/20news_test.vw', 'w',encoding='utf-8') as vw_test_data:\n",
    "    for text in test_documents:\n",
    "        vw_test_data.write(to_vw_format(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустим Vowpal Wabbit на сформированном файле. Мы решаем задачу классификации, поэтому зададим функцию потерь в значение hinge (линейный SVM). Построенную модель мы сохраним в соответствующий файл `20news_model.vw`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "final_regressor = ../../data/news_data/20news_model.vw\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = ../../data/news_data/20news_train.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            1            1.0  -1.0000   0.0000      157\n",
      "0.911276 0.822551            2            2.0  -1.0000  -0.1774      159\n",
      "0.605793 0.300311            4            4.0  -1.0000  -0.3994       92\n",
      "0.419594 0.233394            8            8.0  -1.0000  -0.8167      129\n",
      "0.313998 0.208402           16           16.0  -1.0000  -0.6509      108\n",
      "0.196014 0.078029           32           32.0  -1.0000  -1.0000      115\n",
      "0.183158 0.170302           64           64.0  -1.0000  -0.7072      114\n",
      "0.261046 0.338935          128          128.0   1.0000  -0.7900      110\n",
      "0.262910 0.264774          256          256.0  -1.0000  -0.6425       44\n",
      "0.216663 0.170415          512          512.0  -1.0000  -1.0000      160\n",
      "0.176710 0.136757         1024         1024.0  -1.0000  -1.0000      194\n",
      "0.134541 0.092371         2048         2048.0  -1.0000  -1.0000      438\n",
      "0.104403 0.074266         4096         4096.0  -1.0000  -1.0000      644\n",
      "0.081329 0.058255         8192         8192.0  -1.0000  -1.0000      174\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 8485\n",
      "passes used = 1\n",
      "weighted example sum = 8485.000000\n",
      "weighted label sum = -7555.000000\n",
      "average loss = 0.079837\n",
      "best constant = -1.000000\n",
      "best constant's loss = 0.109605\n",
      "total feature number = 2048932\n"
     ]
    }
   ],
   "source": [
    "!vw -d ../../data/news_data/20news_train.vw \\\n",
    "  --loss_function hinge -f ../../data/news_data/20news_model.vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель обучена. VW выводит достаточно много полезной информации по ходу обучения (тем не менее, ее можно погасить, если задать параметр --quiet). Подробно вывод диагностическйой информации разобран в документации VW на GitHub – [тут](https://github.com/JohnLangford/vowpal_wabbit/wiki/Tutorial#vws-diagnostic-information). Обратите внимание, что average loss снижался по ходу выполнения итераций. Для вычисления функции потерь VW использует еще не просмотренные примеры, поэтому, как правило, эта оценка является корректной. Применим обученную модель на тестовой выборке, сохраняя предсказания в файл с помощью опции -p: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only testing\n",
      "predictions = ../../data/news_data/20news_test_predictions.txt\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = ../../data/news_data/20news_test.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "    n.a.     n.a.            1            1.0  unknown   1.0000      349\n",
      "    n.a.     n.a.            2            2.0  unknown  -1.0000       50\n",
      "    n.a.     n.a.            4            4.0  unknown  -1.0000      251\n",
      "    n.a.     n.a.            8            8.0  unknown  -1.0000      237\n",
      "    n.a.     n.a.           16           16.0  unknown  -0.8978      106\n",
      "    n.a.     n.a.           32           32.0  unknown  -1.0000      964\n",
      "    n.a.     n.a.           64           64.0  unknown  -1.0000      261\n",
      "    n.a.     n.a.          128          128.0  unknown   0.4621       82\n",
      "    n.a.     n.a.          256          256.0  unknown  -1.0000      186\n",
      "    n.a.     n.a.          512          512.0  unknown  -1.0000      162\n",
      "    n.a.     n.a.         1024         1024.0  unknown  -1.0000      283\n",
      "    n.a.     n.a.         2048         2048.0  unknown  -1.0000      104\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 2829\n",
      "passes used = 1\n",
      "weighted example sum = 2829.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = n.a.\n",
      "total feature number = 642215\n"
     ]
    }
   ],
   "source": [
    "!vw -i ../../data/news_data/20news_model.vw -t -d ../../data/news_data/20news_test.vw \\\n",
    "-p ../../data/news_data/20news_test_predictions.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим полученные предсказания, вычислим AUC и отобразим ROC-кривую:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEpCAYAAACurTSFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x169bbbc26d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('../../data/news_data/20news_test_predictions.txt') as pred_file:\n",
    "    test_prediction = [float(label) \n",
    "                             for label in pred_file.readlines()]\n",
    "\n",
    "auc = roc_auc_score(test_labels, test_prediction)\n",
    "roc_curve = roc_curve(test_labels, test_prediction)\n",
    "\n",
    "with plt.xkcd():\n",
    "    plt.plot(roc_curve[0], roc_curve[1]);\n",
    "    plt.plot([0,1], [0,1])\n",
    "    plt.xlabel('FPR'); plt.ylabel('TPR'); plt.title('test AUC = %f' % (auc)); plt.axis([-0.05,1.05,-0.05,1.05]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полученное значения AUC говорит о высоком качестве классификации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Новости. Многоклассовая классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем ту же выборку, что в прошлой части, но решаем задачу многоклассовой классификации. Тут `Vowpal Wabbit` слегка капризничает – он любит, чтоб метки классов были распределены от 1 до K, где K – число классов в задаче классификации (в нашем случае – 20). Поэтому придется применить LabelEncoder, да еще и +1 потом добавить (`LabelEncoder` переводит метки в диапозон от 0 до K-1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_documents = newsgroups['data']\n",
    "topic_encoder = LabelEncoder()\n",
    "all_targets_mult = topic_encoder.fit_transform(newsgroups['target']) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выборки будут те же, а метки поменяются, train_labels_mult и test_labels_mult – векторы меток от 1 до 20.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_documents, test_documents, train_labels_mult, test_labels_mult = \\\n",
    "    train_test_split(all_documents, all_targets_mult, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../../data/news_data/20news_train_mult.vw', 'w', encoding='utf-8') as vw_train_data:\n",
    "    for text, target in zip(train_documents, train_labels_mult):\n",
    "        vw_train_data.write(to_vw_format(text, target))\n",
    "with open('../../data/news_data/20news_test_mult.vw', 'w', encoding='utf-8') as vw_test_data:\n",
    "    for text in test_documents:\n",
    "        vw_test_data.write(to_vw_format(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим Vowpal Wabbit в режиме многоклассовой классификации, передав параметр `oaa` (от \"one against all\"), равный числу классов. Также перечислим параметры, которые можно понастраивать, и от которых качество модели может довольно значительно зависеть (более полно – в официальном [тьюториале](https://github.com/JohnLangford/vowpal_wabbit/wiki/Tutorial) по Vowpal Wabbit):\n",
    " - темп обучения (-l, по умолчанию 0.5) – коэффициент перед изменением весов модели при каждом изменении\n",
    " - степень убывания темпа обучения (--power_t, по умолчанию 0.5) – на практике проверено, что если темп обучения уменьшается при увеличении числа итераций стохастического градиентного спуска, то минимум функции находится лучше \n",
    " - функция потерь (--loss_function) – от нее, по сути, зависит обучаемый алгоритм. Про функции потерь в [документации](https://github.com/JohnLangford/vowpal_wabbit/wiki/Loss-functions)\n",
    " - регуляризация (-l1) – тут надо обратить внимание на то, что в VW регуляризация считается для каждого объекта, поэтому коэффициенты регуляризации обычно берутся малыми, около $10^{-20}.$\n",
    " \n",
    " Дополнительно можно попробовать автоматическую настройку параметров Vowpal Wabbit с Hyperopt. Пока это работает только с Python 2. [Статья](https://habrahabr.ru/company/dca/blog/272697/) на Хабре."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 463 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "final_regressor = ../../data/news_data/20news_model_mult.vw\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = ../../data/news_data/20news_train_mult.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            1            1.0       15        1      157\n",
      "1.000000 1.000000            2            2.0        2       15      159\n",
      "1.000000 1.000000            4            4.0       15       10       92\n",
      "1.000000 1.000000            8            8.0       16       15      129\n",
      "1.000000 1.000000           16           16.0       13       12      108\n",
      "0.937500 0.875000           32           32.0        2        9      115\n",
      "0.906250 0.875000           64           64.0       16       16      114\n",
      "0.867188 0.828125          128          128.0        8        4      110\n",
      "0.816406 0.765625          256          256.0        7       15       44\n",
      "0.646484 0.476563          512          512.0       13        9      160\n",
      "0.502930 0.359375         1024         1024.0        3        4      194\n",
      "0.388672 0.274414         2048         2048.0        1        1      438\n",
      "0.300293 0.211914         4096         4096.0       11       11      644\n",
      "0.225098 0.149902         8192         8192.0        5        5      174\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 8485\n",
      "passes used = 1\n",
      "weighted example sum = 8485.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.222392\n",
      "total feature number = 2048932\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!vw --oaa 20 ../../data/news_data/20news_train_mult.vw \\\n",
    "-f ../../data/news_data/20news_model_mult.vw --loss_function=hinge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 91.1 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "only testing\n",
      "predictions = ../../data/news_data/20news_test_predictions_mult.txt\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = ../../data/news_data/20news_test_mult.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "    n.a.     n.a.            1            1.0  unknown        8      349\n",
      "    n.a.     n.a.            2            2.0  unknown        6       50\n",
      "    n.a.     n.a.            4            4.0  unknown       18      251\n",
      "    n.a.     n.a.            8            8.0  unknown       18      237\n",
      "    n.a.     n.a.           16           16.0  unknown        4      106\n",
      "    n.a.     n.a.           32           32.0  unknown       15      964\n",
      "    n.a.     n.a.           64           64.0  unknown        4      261\n",
      "    n.a.     n.a.          128          128.0  unknown        8       82\n",
      "    n.a.     n.a.          256          256.0  unknown       10      186\n",
      "    n.a.     n.a.          512          512.0  unknown        1      162\n",
      "    n.a.     n.a.         1024         1024.0  unknown       11      283\n",
      "    n.a.     n.a.         2048         2048.0  unknown       14      104\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 2829\n",
      "passes used = 1\n",
      "weighted example sum = 2829.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = n.a.\n",
      "total feature number = 642215\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!vw -i ../../data/news_data/20news_model_mult.vw -t \\\n",
    "-d ../../data/news_data/20news_test_mult.vw \\\n",
    "-p ../../data/news_data/20news_test_predictions_mult.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../../data/news_data/20news_test_predictions_mult.txt') as pred_file:\n",
    "    test_prediction_mult = [float(label) \n",
    "                            for label in pred_file.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8734535171438671"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_labels_mult, test_prediction_mult)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве примера анализа резльтатов, посмотрим, с какими темами классификатор путает атеизм."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rec.autos 1\n",
      "rec.sport.baseball 1\n",
      "sci.med 1\n",
      "soc.religion.christian 3\n",
      "talk.religion.misc 5\n"
     ]
    }
   ],
   "source": [
    "M = confusion_matrix(test_labels_mult, test_prediction_mult)\n",
    "for i in np.where(M[0,:] > 0)[0][1:]:\n",
    "    print(newsgroups['target_names'][i], M[0,i], )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Рецензии к фильмам IMDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой части мы будем заниматься бинарной классификацией отзывов к фильмам, публикованным на сайте IMDB. Обратите внимание, насколько быстро будет работать Vowpal Wabbit.\n",
    "\n",
    "Используем функцию `load_files` из `sklearn.datasets` для загрузки отзывов по фильмам [отсюда](https://yadi.sk/d/Tg1Tflur333iLr). Скачайте данные и укажите свой путь к каталогу `imdb_reviews` (в нем должны быть каталоги *train* и *test*). Разархивирование может занять несколько минут – там 100 тыс. файлов. В обучающей и тестовой выборках по 12500 тысяч хороших и плохих отзывов к фильмам. Отделим данные (собственно, тексты) от меток."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# поменяйте на свой путь\n",
    "path_to_movies = '../../data/imdb_reviews/'\n",
    "reviews_train = load_files(os.path.join(path_to_movies, 'train'))\n",
    "text_train, y_train = reviews_train.data, reviews_train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents in training data: 25000\n",
      "[12500 12500]\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of documents in training data: %d\" % len(text_train))\n",
    "print(np.bincount(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То же самое с тестовой выборкой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents in test data: 25000\n",
      "[12500 12500 50000]\n"
     ]
    }
   ],
   "source": [
    "reviews_test = load_files(os.path.join(path_to_movies, 'test'))\n",
    "text_test, y_test = reviews_test.data, reviews_train.target\n",
    "print(\"Number of documents in test data: %d\" % len(text_test))\n",
    "print(np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примеры отзывов и соответствующих меток"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b\"Dan Katzir has produced a wonderful film that takes us on a roller-coaster ride through a real romance set in the troubles surrounding modern Israel.<br /><br />For anyone who's ever been in love, the film brings back the uncertainties, the insecurities and heartache that make love so bitter-sweet. The atmosphere of fear and isolation that came with the difficult times in Israel at that time just serve to intensify the feeling. Instantly, you are drawn in to Dan's plight, and you can't fail to be deeply moved.<br /><br />You can't write drama and passion like this - the contrast between the realities of Dan's desperate, snatched relationship with Iris, and the realities of a state in turmoil make this eminently watchable. If you have an ounce of passion, and have ever been in love, see this film.\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_train[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 1, 1, 2, 2, 2, 2, 0, 2, 0, 0, 0, 2, 2, 0, 1, 0, 2])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:20] # хороший отзыв"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b\"Amount of disappointment I am getting these days seeing movies like Partner, Jhoom Barabar and now, Heyy Babyy is gonna end my habit of seeing first day shows.<br /><br />The movie is an utter disappointment because it had the potential to become a laugh riot only if the d\\xc3\\xa9butant director, Sajid Khan hadn't tried too many things. Only saving grace in the movie were the last thirty minutes, which were seriously funny elsewhere the movie fails miserably. First half was desperately been tried to look funny but wasn't. Next 45 minutes were emotional and looked totally artificial and illogical.<br /><br />OK, when you are out for a movie like this you don't expect much logic but all the flaws tend to appear when you don't enjoy the movie and thats the case with Heyy Babyy. Acting is good but thats not enough to keep one interested.<br /><br />For the positives, you can take hot actresses, last 30 minutes, some comic scenes, good acting by the lead cast and the baby. Only problem is that these things do not come together properly to make a good movie.<br /><br />Anyways, I read somewhere that It isn't a copy of Three men and a baby but I think it would have been better if it was.\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1] # плохой отзыв"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем использовать ранее написанную функцию `to_vw_format`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-1 |text amount disappointment getting these days seeing movies like partner jhoom barabar and now heyy babyy gonna end habit seeing first day shows the movie utter disappointment because had the potential become laugh riot only the xc3 xa9butant director sajid khan hadn tried too many things only saving grace the movie were the last thirty minutes which were seriously funny elsewhere the movie fails miserably first half was desperately been tried look funny but wasn next minutes were emotional and looked totally artificial and illogical when you are out for movie like this you don expect much logic but all the flaws tend appear when you don enjoy the movie and thats the case with heyy babyy acting good but thats not enough keep one interested for the positives you can take hot actresses last minutes some comic scenes good acting the lead cast and the baby only problem that these things not come together properly make good movie anyways read somewhere that isn copy three men and baby but think would have been better was\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_vw_format(str(text_train[1]), 1 if y_train[0] == 1 else -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим обучающую (`movie_reviews_train.vw`), отложенную (`movie_reviews_valid.vw`) и тестовую (`movie_reviews_test.vw`) выборки для Vowpal Wabbit. 70% исходной обучаюшей выборки оставим под обучение, 30% – под отложенную выборку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_share = int(0.7 * len(text_train))\n",
    "train, valid = text_train[:train_share], text_train[train_share:]\n",
    "train_labels, valid_labels = y_train[:train_share], y_train[train_share:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52500, 22500)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels), len(valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../../data/movie_reviews_train.vw', 'w', encoding='utf-8') as vw_train_data:\n",
    "    for text, target in zip(train, train_labels):\n",
    "        vw_train_data.write(to_vw_format(str(text), 1 if target == 1 else -1))\n",
    "with open('../../data/movie_reviews_valid.vw', 'w', encoding='utf-8') as vw_train_data:\n",
    "    for text, target in zip(valid, valid_labels):\n",
    "        vw_train_data.write(to_vw_format(str(text), 1 if target == 1 else -1))\n",
    "with open('../../data/movie_reviews_test.vw', 'w',encoding='utf-8') as vw_test_data:\n",
    "    for text in text_test:\n",
    "        vw_test_data.write(to_vw_format(str(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 |text full then unknown actors tsf great big cuddly romp film the idea bunch bored teenagers ripping off the local sink factory odd enough but add the black humour that forsyth are good and your for real treat the comatose van driver itself worth seeing and the canal side chase just too real anything but funny and for anyone who lived glasgow great know where that film\n",
      "-1 |text amount disappointment getting these days seeing movies like partner jhoom barabar and now heyy babyy gonna end habit seeing first day shows the movie utter disappointment because had the potential become laugh riot only the xc3 xa9butant director sajid khan hadn tried too many things only saving grace the movie were the last thirty minutes which were seriously funny elsewhere the movie fails miserably first half was desperately been tried look funny but wasn next minutes were emotional and looked totally artificial and illogical when you are out for movie like this you don expect much logic but all the flaws tend appear when you don enjoy the movie and thats the case with heyy babyy acting good but thats not enough keep one interested for the positives you can take hot actresses last minutes some comic scenes good acting the lead cast and the baby only problem that these things not come together properly make good movie anyways read somewhere that isn copy three men and baby but think would have been better was\n"
     ]
    }
   ],
   "source": [
    "!head -2 ../../data/movie_reviews_train.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 |text bank heist goes horribly bad when what else the dead come for food far recent urban zombie movies dead heist better than zombiez but worse than hood the living dead and gangs the dead that not saying much especially when you consider the fact that hood and gangs are bad movies too the dead here are cut from the same cloth the speedy zombies from the dawn the dead remake and the infected from days later and sequel only generic instead interesting frightening the gore nothing new though the fact that the dead can only killed being shot the heart and you blame poor attempt trying something different far acting goes big daddy kane does the best job not good mind you but does the best job amusingly while bone crusher and are advertised staring yet they aren the movie for very long bone crusher appears the beginning patron strip club tame could have passed for mtv the grind then disappears meanwhile has less than minutes screen time porn director and gives alright where paycheck already level performance the rest the cast ranges from dead ringer for vin diesel the white female cop white businessman thinking joining the nation islam and plenty stereotypical gang banger characters while not the worst recent urban horror movie there still nothing worth recommending here have idea whether not the fact that this reminded the attack the street pimps bit from hollywood shuffle good thing bad thing probably bad thing\n",
      "1 |text without doubt monkeys one the best films the sci genre and director terry gilliam stranger pulling off such cinematic originality apocalyptic film that holds you completely spellbound monkeys never lets and has you guessing all the way throughout excellent use philadelphia locales and netherworld sets create gothic sense tragedy and two people caught time the wrong place bruce willis escapes his macho image and portrays true loony who happens right about all that will happen actually sane but the people the future present you will distort this guy head bad through time travel wonder unravels gets sent world war just after beng sent the wrong year find out how the army the twelve monkeys pulls off the annihilation civilization know they finally get right and what truly remarkable screenplay match the performance get see willis madeleine stowe and ominous brad pitt cross referenced over the course years stowe sensual and solid the risk taking shrink who slowly starts realize that willis may not cracked seems captivating element the relationship between her and willis their sense seeing each other before another place time monkeys essentially about time and the madness the futuristic people immerse into and the times the present when killers and psychotic genius can alter the world the brooding city philadelphia dark and gothic backdrop for willis plight complete his mission which against all usual hollywood stereotype not save the world gathering information the film plays tricks the viewer well placing willis new setting the drop pin this must have been extremely difficult picture make but gilliam seems the master hard boiled movie making even drops some humor reminiscent other great works like time bandits and brazil the screen this man canvas and knows how paint sometimes terrifying picture the world and its possible future within the mainstream atmosphere big budget films you want sincere madness and ironic tragedy see monkeys rating\n"
     ]
    }
   ],
   "source": [
    "!head -2 ../../data/movie_reviews_valid.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |text don hate heather graham because she beautiful hate her because she fun watch this movie like the hip clothing and funky surroundings the actors this flick work well together casey affleck hysterical and heather graham literally lights the screen the minor characters goran visnjic sigh and patricia velazquez are talented they are gorgeous congratulations miramax director lisa krueger\n",
      " |text don know how this movie has received many positive comments one can call artistic and beautifully filmed but those things don make for the empty plot that was filled with sexual innuendos wish had not wasted time watch this movie rather than being biographical was poor excuse for promoting strange and lewd behavior was just another hollywood attempt convince that that kind life normal and from the very beginning asked self what was the point this movie and continued watching hoping that would change and was quite disappointed that continued the same vein glad did not spend the money see this theater\n"
     ]
    }
   ],
   "source": [
    "!head -2 ../../data/movie_reviews_test.vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обучим модель Vowpal Wabbit со следующими агрументами:**\n",
    "\n",
    " - -d, путь к обучающей выборке (соотв. файл .vw )\n",
    " - --loss_function – hinge (хотя можно и поэкспериментировать с другими)\n",
    " - -f – путь к файлу, в который запишется модель (можно тоже в формате .vw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!vw -d ../../data/movie_reviews_train.vw \\\n",
    "--loss_function hinge -f movie_reviews_model.vw --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем прогноз для отложенной выборки с помощью обученной модели Vowpal Wabbit, передав следующие аргументы:\n",
    " - -i –путь к обученной модели (соотв. файл .vw)\n",
    " - -t -d – путь к отложенной выборке (соотв. файл .vw)\n",
    " - -p – путь к txt-файлу, куда запишутся прогнозы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!vw -i movie_reviews_model.vw -t -d ../../data/movie_reviews_valid.vw \\\n",
    "-p movie_valid_pred.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем прогноз из файла и посчитаем долю правильных ответов и ROC AUC. Учтем, что VW выводит оценки вероятности принадлежности к классу +1. Эти оценки распределены на [-1, 1], поэтому бинарным ответом алгоритма (0 или 1) будем попросту считать тот факт, что оценка получилась положительной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.213\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "multiclass format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-89f2b7d9f95b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m print(\"Accuracy: {}\".format(round(accuracy_score(valid_labels, \n\u001b[0;32m      5\u001b[0m                [int(pred_prob > 0) for pred_prob in valid_prediction]), 3)))\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"AUC: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_prediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mG:\\Python\\lib\\site-packages\\sklearn\\metrics\\ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m    275\u001b[0m     return _average_binary_score(\n\u001b[0;32m    276\u001b[0m         \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 277\u001b[1;33m         sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Python\\lib\\site-packages\\sklearn\\metrics\\base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[1;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[0my_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multilabel-indicator\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{0} format is not supported\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: multiclass format is not supported"
     ]
    }
   ],
   "source": [
    "with open('movie_valid_pred.txt', encoding='utf-8') as pred_file:\n",
    "    valid_prediction = [float(label) \n",
    "                             for label in pred_file.readlines()]\n",
    "print(\"Accuracy: {}\".format(round(accuracy_score(valid_labels, \n",
    "               [int(pred_prob > 0) for pred_prob in valid_prediction]), 3)))\n",
    "print(\"AUC: {}\".format(round(roc_auc_score(valid_labels, valid_prediction), 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Сделаем то же самое для тестовой выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!vw -i movie_reviews_model.vw -t -d ../../data/movie_reviews_test.vw \\\n",
    "-p movie_test_pred.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [75000, 25000]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-c758a7a91dba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m                              for label in pred_file.readlines()]\n\u001b[0;32m      4\u001b[0m print(\"Accuracy: {}\".format(round(accuracy_score(y_test, \n\u001b[1;32m----> 5\u001b[1;33m                [int(pred_prob > 0) for pred_prob in test_prediction]), 3)))\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"AUC: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_prediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Python\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[0mdiffering_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount_nonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Python\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \"\"\"\n\u001b[1;32m---> 71\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Python\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 204\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [75000, 25000]"
     ]
    }
   ],
   "source": [
    "with open('movie_test_pred.txt') as pred_file:\n",
    "    test_prediction = [float(label) \n",
    "                             for label in pred_file.readlines()]\n",
    "print(\"Accuracy: {}\".format(round(accuracy_score(y_test, \n",
    "               [int(pred_prob > 0) for pred_prob in test_prediction]), 3)))\n",
    "print(\"AUC: {}\".format(round(roc_auc_score(y_test, test_prediction), 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем улучшить прогноз за счет задействования биграмм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!vw -d ../../data/movie_reviews_train.vw \\\n",
    "--loss_function hinge --ngram 2 -f movie_reviews_model2.vw --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!vw -i movie_reviews_model2.vw -t -d ../../data/movie_reviews_valid.vw \\\n",
    "-p movie_valid_pred2.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.894\n",
      "AUC: 0.954\n"
     ]
    }
   ],
   "source": [
    "with open('movie_valid_pred2.txt') as pred_file:\n",
    "    valid_prediction = [float(label) \n",
    "                             for label in pred_file.readlines()]\n",
    "print(\"Accuracy: {}\".format(round(accuracy_score(valid_labels, \n",
    "               [int(pred_prob > 0) for pred_prob in valid_prediction]), 3)))\n",
    "print(\"AUC: {}\".format(round(roc_auc_score(valid_labels, valid_prediction), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!vw -i movie_reviews_model2.vw -t -d ../../data/movie_reviews_test.vw \\\n",
    "-p movie_test_pred2.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.888\n",
      "AUC: 0.952\n"
     ]
    }
   ],
   "source": [
    "with open('movie_test_pred2.txt') as pred_file:\n",
    "    test_prediction2 = [float(label) \n",
    "                             for label in pred_file.readlines()]\n",
    "print(\"Accuracy: {}\".format(round(accuracy_score(y_test, \n",
    "               [int(pred_prob > 0) for pred_prob in test_prediction2]), 3)))\n",
    "print(\"AUC: {}\".format(round(roc_auc_score(y_test, test_prediction2), 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что биграммы помогли повысить качество классификации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Классификация вопросов на StackOverflow "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь посмотрим, как в действительности Vowpal Wabbit справляется с большими выборками. Имеются 10 Гб вопросов со StackOverflow – [ссылка](https://cloud.mail.ru/public/3bwi/bFYHDN5S5) на данные, там аккурат 10 миллионов вопросов, и у каждого вопроса может быть несколько тегов. Данные довольно чистые, и не называйте это бигдатой даже в пабе :)\n",
    "\n",
    "<img src='../../img/say_big_data.jpg' width=50%>\n",
    "\n",
    "Из всех тегов выделены 10, и решается задача классификации на 10 классов: по тексту вопроса надо поставить один из 10 тегов, соответствующих 10 популярным языкам программирования. Предобработанные данные не даются, поскольку их надо получить в домашней работе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# поменяйте путь к данным\n",
    "PATH_TO_DATA = '/Users/y.kashnitsky/Documents/Machine_learning/org_mlcourse_open/private/stackoverflow_hw/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,4G\t/Users/y.kashnitsky/Documents/Machine_learning/org_mlcourse_open/private/stackoverflow_hw//stackoverflow_10mln_test.vw\r\n",
      "3,3G\t/Users/y.kashnitsky/Documents/Machine_learning/org_mlcourse_open/private/stackoverflow_hw//stackoverflow_10mln_train.vw\r\n",
      "1,9G\t/Users/y.kashnitsky/Documents/Machine_learning/org_mlcourse_open/private/stackoverflow_hw//stackoverflow_10mln_train_part.vw\r\n",
      "1,4G\t/Users/y.kashnitsky/Documents/Machine_learning/org_mlcourse_open/private/stackoverflow_hw//stackoverflow_10mln_valid.vw\r\n"
     ]
    }
   ],
   "source": [
    "!du -hs $PATH_TO_DATA/stackoverflow_10mln_*.vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот как выглядят строки, на которых будет обучаться Vowpal Wabbit. 10 означает 10 класс, далее вертикальная черта и просто текст вопроса. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 | i ve got some code in window scroll that checks if an element is visible then triggers another function however only the first section of code is firing both bits of code work in and of themselves if i swap their order whichever is on top fires correctly my code is as follows fn isonscreen function use strict var win window viewport top win scrolltop left win scrollleft bounds this offset viewport right viewport left + win width viewport bottom viewport top + win height bounds right bounds left + this outerwidth bounds bottom bounds top + this outerheight return viewport right lt bounds left viewport left gt bounds right viewport bottom lt bounds top viewport top gt bounds bottom window scroll function use strict var load_more_results ajax load_more_results isonscreen if load_more_results true loadmoreresults var load_more_staff ajax load_more_staff isonscreen if load_more_staff true loadmorestaff what am i doing wrong can you only fire one event from window scroll i assume not\r\n"
     ]
    }
   ],
   "source": [
    "!head -1 $PATH_TO_DATA/stackoverflow_10mln_train.vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим на обучающей части выборки (3.3 Гб) модель Vowpal Wabbit со следующими аргументами: \n",
    "- -oaa 10 – указываем, что классификация на 10 классов \n",
    "- -d – путь к данным \n",
    "- -f – путь к модели, которая будет построена \n",
    "- -b 28 – используем 28 бит для хэширования, то есть признаковое пространство ограничено $2^{28}$ признаками, что в данном случае больше, чем число уникальных слов в выборке (но потом появятся би- и триграммы, и ограничение размерности признакового пространства начнет работать)\n",
    "- также указываем random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 706 ms, sys: 256 ms, total: 962 ms\n",
      "Wall time: 43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!vw --oaa 10 -d $PATH_TO_DATA/stackoverflow_10mln_train.vw \\\n",
    "-f vw_model1_10mln.vw -b 28 --random_seed 17 --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметим, что модель обучилась всего за 43 секунды, для тестовой выборки прогнозы сделала еще за 15 секунд, доля правильных ответов – почти 92%. Далее качество модели можно повышать за счет нескольких проходов по выборке, задействования биграмм и настройке параметров. Это вместе с предобработкой данных и будет второй частью домашнего задания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 231 ms, sys: 90.5 ms, total: 322 ms\n",
      "Wall time: 14.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!vw -t -i vw_model1_10mln.vw \\\n",
    "-d $PATH_TO_DATA/stackoverflow_10mln_test.vw \\\n",
    "-p vw_valid_10mln_pred1.csv --random_seed 17 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91868709729356979"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "vw_pred = np.loadtxt('vw_valid_10mln_pred1.csv')\n",
    "test_labels = np.loadtxt(os.path.join(PATH_TO_DATA, \n",
    "                                      'stackoverflow_10mln_test_labels.txt'))\n",
    "accuracy_score(test_labels, vw_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание\n",
    "В этот раз задание будет большим. В первой части, чтоб вам не казалось, что Vowpal Wabbit – это какая-то магия, вы реализуете самостоятельно классификатор и регрессор, обучаемые стохастическим градиентным спуском.\n",
    "\n",
    "Во второй части вам предлагается взять набор данных (10 Гб), содержащий вопросы на StackOverflow и теги этих вопросов, предобработать данные (подумав над эффективность совершаемых операций) и построить классификатор вопросов по 10 тегам (по 10 языкам программирования). Возможно, вы уже удивились, как простая модель VW может обучиться на такой выборке за секунды или минуты на простом железе, без всяких Hadoop-кластеров. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Полезные ссылки\n",
    "- материалы Евгения Соколова: [Многоклассовая классификация и категориальные признаки](https://github.com/esokolov/ml-course-hse/blob/master/2016-fall/lecture-notes/lecture06-linclass.pdf) (там же про хэширование признаков), [Линейная регрессия](https://github.com/esokolov/ml-course-hse/blob/master/2016-fall/lecture-notes/lecture02-linregr.pdf) (там же про градиентный спуск и его стохастическую версию), [презентация](https://github.com/esokolov/ml-course-msu/blob/master/ML15/lecture-notes/Sem08_vw.pdf) про Vowpal Wabbit\n",
    "- [Глава](http://www.deeplearningbook.org/contents/numerical.html) \"Numeric Computation\" книги \"Deep Learning\"\n",
    "- Обширная [документация](https://github.com/JohnLangford/vowpal_wabbit/wiki) Vowpal Wabbit на GitHub\n",
    "- Минималистичная [статья](https://habrahabr.ru/company/mlclass/blog/248779/) на Хабре про VW\n",
    "- [Статья](https://habrahabr.ru/company/dca/blog/272697/) на Хабре про связку VW и hyperopt "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
